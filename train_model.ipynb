{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880c97f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
      "     -------------------------------------- 331.8/331.8 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.5-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "Collecting Pillow\n",
      "  Using cached pillow-12.0.0-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "     ---------------------------------------- 8.1/8.1 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting streamlit\n",
      "  Using cached streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "     -------------------------------------- 135.8/135.8 kB 8.4 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting google_pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting opt_einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (25.0)\n",
      "Collecting protobuf>=5.28.0\n",
      "  Using cached protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from tensorflow->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-2.0.1-cp311-cp311-win_amd64.whl (60 kB)\n",
      "     ---------------------------------------- 60.4/60.4 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 8.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard~=2.20.0\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting keras>=3.10.0\n",
      "  Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 7.8 MB/s eta 0:00:00\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.15.1-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "     ---------------------------------------- 2.9/2.9 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1\n",
      "  Downloading ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "     -------------------------------------- 210.7/210.7 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Collecting pyparsing>=3\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "     -------------------------------------- 113.9/113.9 kB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0\n",
      "  Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Collecting blinker<2,>=1.5.0\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting cachetools<7,>=4.0\n",
      "  Using cached cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting click<9,>=7.0\n",
      "  Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Collecting pandas<3,>=1.4.0\n",
      "  Using cached pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "Collecting pyarrow<22,>=7.0\n",
      "  Using cached pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "Collecting tenacity<10,>=8.1.0\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting watchdog<7,>=2.1.5\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 5)) (6.5.2)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting jsonschema>=3.0\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Using cached narwhals-2.12.0-py3-none-any.whl (425 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "     ---------------------------------------- 72.5/72.5 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit->-r requirements.txt (line 5)) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "     -------------------------------------- 243.4/243.4 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Collecting optree\n",
      "  Downloading optree-0.18.0-cp311-cp311-win_amd64.whl (312 kB)\n",
      "     -------------------------------------- 312.2/312.2 kB 9.7 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "     -------------------------------------- 107.7/107.7 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Collecting attrs>=22.2.0\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.29.0-cp311-cp311-win_amd64.whl (235 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.3/87.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aqilw\\desktop\\project\\ai-detector\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow->-r requirements.txt (line 1)) (2.19.2)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, watchdog, urllib3, tzdata, toml, termcolor, tensorboard-data-server, tenacity, smmap, rpds-py, pyparsing, pyarrow, protobuf, Pillow, optree, opt_einsum, numpy, narwhals, mdurl, MarkupSafe, markdown, kiwisolver, idna, grpcio, google_pasta, gast, fonttools, cycler, click, charset_normalizer, certifi, cachetools, blinker, attrs, absl-py, werkzeug, requests, referencing, pandas, ml_dtypes, markdown-it-py, jinja2, h5py, gitdb, contourpy, astunparse, tensorboard, rich, pydeck, matplotlib, jsonschema-specifications, gitpython, keras, jsonschema, tensorflow, altair, streamlit\n",
      "Successfully installed MarkupSafe-3.0.3 Pillow-12.0.0 absl-py-2.3.1 altair-5.5.0 astunparse-1.6.3 attrs-25.4.0 blinker-1.9.0 cachetools-6.2.2 certifi-2025.11.12 charset_normalizer-3.4.4 click-8.3.1 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.9.23 fonttools-4.60.1 gast-0.6.0 gitdb-4.0.12 gitpython-3.1.45 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 idna-3.11 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 keras-3.12.0 kiwisolver-1.4.9 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 narwhals-2.12.0 numpy-2.3.5 opt_einsum-3.4.0 optree-0.18.0 pandas-2.3.3 protobuf-6.33.1 pyarrow-21.0.0 pydeck-0.9.1 pyparsing-3.2.5 pytz-2025.2 referencing-0.37.0 requests-2.32.5 rich-14.2.0 rpds-py-0.29.0 smmap-5.0.2 streamlit-1.51.0 tenacity-9.1.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 toml-0.10.2 tzdata-2025.2 urllib3-2.5.0 watchdog-6.0.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490e991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 777 images belonging to 2 classes.\n",
      "Found 193 images belonging to 2 classes.\n",
      "Class indices: {'ai': 0, 'real': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ last_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,592</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ last_conv (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m6,422,592\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,515,905</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,515,905\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,515,905</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,515,905\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m18/49\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 565ms/step - accuracy: 0.5963 - loss: 1.1776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aqilw\\Desktop\\project\\AI-Detector\\.venv\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 681ms/step - accuracy: 0.5727 - loss: 0.7669 - val_accuracy: 0.5544 - val_loss: 0.6535\n",
      "Epoch 2/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 487ms/step - accuracy: 0.6165 - loss: 0.6683 - val_accuracy: 0.5803 - val_loss: 0.6783\n",
      "Epoch 3/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 470ms/step - accuracy: 0.6100 - loss: 0.6459 - val_accuracy: 0.6788 - val_loss: 0.6286\n",
      "Epoch 4/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 478ms/step - accuracy: 0.7001 - loss: 0.5797 - val_accuracy: 0.6425 - val_loss: 0.6203\n",
      "Epoch 5/5\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 463ms/step - accuracy: 0.7722 - loss: 0.4804 - val_accuracy: 0.6632 - val_loss: 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model saved to models/ai_detector_model.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "DATA_DIR = \"data\"          \n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5                 \n",
    "MODEL_PATH = \"models/ai_detector_model.h5\"\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# DATA: AUTO TRAIN/VAL SPLIT \n",
    "# -----------------------\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2  \n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",     #\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"    \n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_gen.class_indices)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# SIMPLE CNN MODEL\n",
    "# -----------------------\n",
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Last conv block \n",
    "    x = layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"last_conv\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # binary: ai vs real\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_model(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -----------------------\n",
    "# TRAIN\n",
    "# -----------------------\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# SAVE MODEL\n",
    "# -----------------------\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"[INFO] Model saved to {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
